{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from implementations import *\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import load_csv_data\n",
    "from processing import clean_data, standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of the data\n",
    "Import of the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30) (250000,)\n"
     ]
    }
   ],
   "source": [
    "y_train, x_train, id_train = load_csv_data(\"../data/train.csv\")\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = np.genfromtxt(\"../data/train.csv\",\n",
    "              delimiter=',',\n",
    "              encoding='UTF-8-sig',\n",
    "              dtype=None,\n",
    "              names=True).dtype.names[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30) (568238,)\n"
     ]
    }
   ],
   "source": [
    "y_test, x_test, id_test = load_csv_data(\"../data/test.csv\")\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "We pre process the data to get a clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.07398883,  0.09429484,  0.61533879, ..., -0.47463072,\n",
       "        -0.51655392,  0.79217235],\n",
       "       [ 1.32752548,  0.28741243,  0.67636725, ..., -0.48873678,\n",
       "        -0.48862393,  0.03302941],\n",
       "       [ 0.77990572,  1.34146227,  0.9327364 , ..., -0.48873678,\n",
       "        -0.48862393,  0.01074183],\n",
       "       ...,\n",
       "       [ 0.70144218,  0.19440272,  0.36720758, ..., -0.48873678,\n",
       "        -0.48862393, -0.01475064],\n",
       "       [ 0.58288357, -0.27012672,  0.28790896, ..., -0.48873678,\n",
       "        -0.48862393, -0.48862393],\n",
       "       [ 0.77990572,  0.3324164 ,  0.31069307, ..., -0.48873678,\n",
       "        -0.48862393, -0.48862393]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cleaned, _, _ = standardize(clean_data(x_train))\n",
    "x_train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509968\n"
     ]
    }
   ],
   "source": [
    "weight, loss = least_squares(y_train, x_train_cleaned)\n",
    "print(compute_mse_loss(y_train, x_train_cleaned, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares with ridges regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509968\n"
     ]
    }
   ],
   "source": [
    "weight, loss = ridge_regression(y_train, x_train_cleaned, 10)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n",
      "(250000, 30) (250000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.24932"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, loss = mean_squared_error_gd(y_train, x_train_cleaned, np.ones((30,)), 100, 1e-4)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74884"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, loss = mean_squared_error_sgd(y_train, x_train_cleaned, np.ones((30,)), 100, 1e-4)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/MLprojec1/scripts/implementations.py:179: RuntimeWarning: overflow encountered in exp\n",
      "  loss = np.log(1 + np.exp(tx @ w)) - y * (tx @ w)\n",
      "/Users/mac/Desktop/MLprojec1/scripts/implementations.py:161: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(t) / (1 + np.exp(t))\n",
      "/Users/mac/Desktop/MLprojec1/scripts/implementations.py:161: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.exp(t) / (1 + np.exp(t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " nan)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(y_train, x_train_cleaned, np.ones((30,)), 100, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def logistic_regression(\n",
    "    y: np.ndarray, tx: np.ndarray, initial_w: np.ndarray, max_iters: int, gamma: float\n",
    ") -> list[np.ndarray, float]:\n",
    "    # init parameters\n",
    "    threshold = 1e-8\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    # start the logistic regression\n",
    "    for iter in range(max_iters):\n",
    "        # get loss and update w.\n",
    "        loss, gradient = calculate_nll_loss(y, tx, w), calculate_logistic_gradient(\n",
    "            y, tx, w\n",
    "        )\n",
    "        w = w - gamma * gradient\n",
    "\n",
    "        # log info\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Current iteration={i}, loss={l}\".format(i=iter, l=loss))\n",
    "        # converge criterion\n",
    "        losses.append(loss)\n",
    "        if len(losses) > 1 and np.abs(losses[-1] - losses[-2]) < threshold:\n",
    "            break\n",
    "    return w, losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.38470e+02,  5.16550e+01,  9.78270e+01, ...,  1.24000e+00,\n",
       "        -2.47500e+00,  1.13497e+02],\n",
       "       [ 1.60937e+02,  6.87680e+01,  1.03235e+02, ..., -1.00000e-02,\n",
       "        -0.00000e+00,  4.62260e+01],\n",
       "       [ 1.12410e+02,  1.62172e+02,  1.25953e+02, ..., -1.00000e-02,\n",
       "        -0.00000e+00,  4.42510e+01],\n",
       "       ...,\n",
       "       [ 1.05457e+02,  6.05260e+01,  7.58390e+01, ..., -1.00000e-02,\n",
       "        -0.00000e+00,  4.19920e+01],\n",
       "       [ 9.49510e+01,  1.93620e+01,  6.88120e+01, ..., -1.00000e-02,\n",
       "        -0.00000e+00,  0.00000e+00],\n",
       "       [ 1.12410e+02,  7.27560e+01,  7.08310e+01, ..., -1.00000e-02,\n",
       "        -0.00000e+00,  0.00000e+00]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_nll_loss(y: np.ndarray, tx: np.ndarray, w: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    compute the cost by negative log likelihood.\n",
    "\n",
    "    Args:\n",
    "        y:  shape=(N, 1)\n",
    "        tx: shape=(N, D)\n",
    "        w:  shape=(D, 1)\n",
    "\n",
    "    Returns:\n",
    "        a non-negative loss: float\n",
    "    \"\"\"\n",
    "    assert y.shape[0] == tx.shape[0]\n",
    "    assert tx.shape[1] == w.shape[0]\n",
    "\n",
    "    loss = np.log(1 + np.exp(tx @ w)) - y * (tx @ w)\n",
    "    return np.mean(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
